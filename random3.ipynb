{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_features = []\n",
    "for i in range (0,4):\n",
    "    for j in range (0,4):\n",
    "        for k in range (0,4):\n",
    "            for w in range (0,4):\n",
    "                list_features.append([i,j,k,w])\n",
    "#print (np.shape(list_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import groupby\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "####### READING THE FASTA CHAIN DATA FROM THE FILE ############\n",
    "def fasta_iter(name):\n",
    "    fh = open(name)\n",
    "\n",
    "    faiter = (x[1] for x in groupby(fh, lambda line: line[0] == \">\"))\n",
    "\n",
    "    for header in faiter:\n",
    "        # drop the \">\"\n",
    "        headerStr = header.__next__()[1:].strip()\n",
    "\n",
    "        # join all sequence lines to one.\n",
    "        seq = \"\".join(s.strip() for s in faiter.__next__())\n",
    "\n",
    "        yield (headerStr, seq)\n",
    "\n",
    "data=fasta_iter(\"Ecoli_prom.fa.txt\")\n",
    "training_data1=[]\n",
    "training_data2=[]\n",
    "\n",
    "\n",
    "######## CONVERTING DNA SEQUENCE INTO ONE HOT ENCODING ##########\n",
    "\n",
    "for chain in data:\n",
    "    headerStr, seq = chain\n",
    "    temp=[]\n",
    "    for i in range (len(seq)-4):\n",
    "        temp1 = []\n",
    "        for j in range (0,4):\n",
    "            if(seq[i+j]=='A'):\n",
    "                temp1.append(0)\n",
    "            if(seq[i+j]=='T'):\n",
    "                temp1.append(1)\n",
    "            if(seq[i+j]=='G'):\n",
    "                temp1.append(2)\n",
    "            if(seq[i+j]=='C'):\n",
    "                temp1.append(3)\n",
    "        temp.append(temp1)\n",
    "    training_data1.append(temp)\n",
    "       \n",
    "    \n",
    "    \n",
    "data=fasta_iter(\"Ecoli_non_prom.fa.txt\")\n",
    "for chain in data:\n",
    "    headerStr, seq = chain\n",
    "    temp=[]\n",
    "    for i in range (len(seq)-4):\n",
    "        temp1 = []\n",
    "        for j in range (0,4):\n",
    "            if(seq[i+j]=='A'):\n",
    "                temp1.append(0)\n",
    "            if(seq[i+j]=='T'):\n",
    "                temp1.append(1)\n",
    "            if(seq[i+j]=='G'):\n",
    "                temp1.append(2)\n",
    "            if(seq[i+j]=='C'):\n",
    "                temp1.append(3)\n",
    "        #print (temp1)\n",
    "        temp.append(temp1)\n",
    "    training_data2.append(temp)\n",
    "#training_data\n",
    "list_freq1 = []\n",
    "list_freq2 = []\n",
    "\n",
    "for i in training_data1:\n",
    "    temp = []\n",
    "    for j in range (len(list_features)):\n",
    "        temp.append(0)\n",
    "    for j in i:\n",
    "        for k in range (len(list_features)):\n",
    "            if (list_features[k]==j):\n",
    "                temp[k] += 1\n",
    "    list_freq1.append(temp)\n",
    "    \n",
    "for i in training_data2:\n",
    "    temp = []\n",
    "    for j in range (len(list_features)):\n",
    "        temp.append(0)\n",
    "    for j in i:\n",
    "        for k in range (len(list_features)):\n",
    "            if (list_features[k]==j):\n",
    "                temp[k] += 1\n",
    "    list_freq2.append(temp)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(839, 256)\n",
      "(839,)\n"
     ]
    }
   ],
   "source": [
    "########### CREATING LABELS FOR THE OUTPUT ###########\n",
    "labels1=[]\n",
    "labels2=[]\n",
    "\n",
    "for i in range(839):\n",
    "    labels1.append(1)\n",
    "for i in range(3000):\n",
    "    labels2.append(0)\n",
    "\n",
    "#### SHUFFLE THE DATA ########    \n",
    "\n",
    "comb=list(zip(list_freq1,labels1))\n",
    "random.shuffle(comb)\n",
    "list_freq1,labels1=zip(*comb)\n",
    "\n",
    "comb=list(zip(list_freq2,labels2))\n",
    "random.shuffle(comb)\n",
    "list_freq2,labels2=zip(*comb)\n",
    "\n",
    "print(np.shape(list_freq1))\n",
    "print(np.shape(labels1))\n",
    "\n",
    "#training_data=np.reshape(training_data,(3839,77*16))\n",
    "\n",
    "#print(np.shape(training_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####### SPLITTING DATA INTO TRAIN,VALIDATION AND TEST ############\n",
    "X_train=list()\n",
    "Y_train=list()\n",
    "for i in range(649):\n",
    "    X_train.append(list_freq1[i])\n",
    "    Y_train.append(labels1[i])\n",
    "for i in range(2480):\n",
    "    X_train.append(list_freq2[i])\n",
    "    Y_train.append(labels2[i])\n",
    "\n",
    "\n",
    "# X_train.append(list(list_freq1[:649]))\n",
    "# Y_train.append(list(labels1[:649]))\n",
    "# X_train.append(list(list_freq2[:2480]))\n",
    "# Y_train.append(list(labels2[:2480]))\n",
    "\n",
    "comb=list(zip(X_train,Y_train))\n",
    "random.shuffle(comb)\n",
    "X_train,Y_train=zip(*comb)\n",
    "\n",
    "X_validation=[]\n",
    "Y_validation=[]\n",
    "\n",
    "for i in range(649,720):\n",
    "    X_validation.append(list_freq1[i])\n",
    "    Y_validation.append(labels1[i])\n",
    "for i in range(2480,2740):\n",
    "    X_validation.append(list_freq2[i])\n",
    "    Y_validation.append(labels2[i])\n",
    "# X_validation.append(list_freq1[649:720])\n",
    "# Y_validation.append(labels1[:720])\n",
    "# X_validation.append(list_freq2[2480:2740])\n",
    "# Y_validation.append(labels2[2480:2740])\n",
    "\n",
    "comb=list(zip(X_validation,Y_validation))\n",
    "random.shuffle(comb)\n",
    "X_validation,Y_validation=zip(*comb)\n",
    "\n",
    "X_test=[]\n",
    "Y_test=[]\n",
    "for i in range(720,839):\n",
    "    X_test.append(list_freq1[i])\n",
    "    Y_test.append(labels1[i])\n",
    "for i in range(2740,3000):\n",
    "    X_test.append(list_freq2[i])\n",
    "    Y_test.append(labels2[i])\n",
    "# X_test.append(list_freq1[720:])\n",
    "# Y_test.append(labels1[720:])\n",
    "# X_test.append(list_freq2[2740:])\n",
    "# Y_test.append(labels2[2740:])\n",
    "\n",
    "comb=list(zip(X_test,Y_test))\n",
    "random.shuffle(comb)\n",
    "X_test,Y_test=zip(*comb)\n",
    "\n",
    "\n",
    "# X_train=list(X_train)\n",
    "# np.shape(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vinayak/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n",
      "/home/vinayak/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/vinayak/anaconda3/lib/python3.6/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.grid_search import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nparameters1 = {\\n              'min_samples_leaf': [1,2,3], \\n              'n_estimators': [32,40]\\n             }\\nrfc = RandomForestClassifier(random_state=42)\\nCV_rfc = GridSearchCV(estimator=rfc,param_grid=parameters1,cv=5)\\nCV_rfc.fit(X_train,Y_train)\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "parameters1 = {\n",
    "              'min_samples_leaf': [1,2,3], \n",
    "              'n_estimators': [32,40]\n",
    "             }\n",
    "rfc = RandomForestClassifier(random_state=42)\n",
    "CV_rfc = GridSearchCV(estimator=rfc,param_grid=parameters1,cv=5)\n",
    "CV_rfc.fit(X_train,Y_train)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=20, max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=6, min_samples_split=10,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0, warm_start=True)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'bootstrap': True,\n",
    "              'min_samples_leaf':6,\n",
    "              'n_estimators': 500, \n",
    "              'min_samples_split': 10,\n",
    "              'max_features': None,\n",
    "              'max_depth': 20,\n",
    "              'warm_start':True\n",
    "             }\n",
    "\n",
    "RF_model = RandomForestClassifier(**parameters)\n",
    "RF_model.fit(X_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96.51645893256632\n"
     ]
    }
   ],
   "source": [
    "RF_predictions = RF_model.predict(X_train)\n",
    "score = accuracy_score(Y_train ,RF_predictions)\n",
    "print(score*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89.12386706948641\n"
     ]
    }
   ],
   "source": [
    "RF_predictions = RF_model.predict(X_validation)\n",
    "score = accuracy_score(Y_validation ,RF_predictions)\n",
    "print(score*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88.91820580474933\n"
     ]
    }
   ],
   "source": [
    "RF_predictions = RF_model.predict(X_test)\n",
    "score = accuracy_score(Y_test ,RF_predictions)\n",
    "print(score*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
