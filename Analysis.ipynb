{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_features = []\n",
    "for i in range (0,4):\n",
    "    for j in range (0,4):\n",
    "        for k in range (0,4):\n",
    "            for w in range (0,4):\n",
    "                list_features.append([i,j,k,w])\n",
    "#print (np.shape(list_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import groupby\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "####### READING THE FASTA CHAIN DATA FROM THE FILE ############\n",
    "def fasta_iter(name):\n",
    "    fh = open(name)\n",
    "\n",
    "    faiter = (x[1] for x in groupby(fh, lambda line: line[0] == \">\"))\n",
    "\n",
    "    for header in faiter:\n",
    "        # drop the \">\"\n",
    "        headerStr = header.__next__()[1:].strip()\n",
    "\n",
    "        # join all sequence lines to one.\n",
    "        seq = \"\".join(s.strip() for s in faiter.__next__())\n",
    "\n",
    "        yield (headerStr, seq)\n",
    "\n",
    "data=fasta_iter(\"Ecoli_prom.fa.txt\")\n",
    "training_data1=[]\n",
    "training_data2=[]\n",
    "\n",
    "\n",
    "######## CONVERTING DNA SEQUENCE INTO ONE HOT ENCODING ##########\n",
    "\n",
    "for chain in data:\n",
    "    headerStr, seq = chain\n",
    "    temp=[]\n",
    "    for i in range (len(seq)-4):\n",
    "        temp1 = []\n",
    "        for j in range (0,4):\n",
    "            if(seq[i+j]=='A'):\n",
    "                temp1.append(0)\n",
    "            if(seq[i+j]=='T'):\n",
    "                temp1.append(1)\n",
    "            if(seq[i+j]=='G'):\n",
    "                temp1.append(2)\n",
    "            if(seq[i+j]=='C'):\n",
    "                temp1.append(3)\n",
    "        temp.append(temp1)\n",
    "    training_data1.append(temp)\n",
    "       \n",
    "    \n",
    "    \n",
    "data=fasta_iter(\"Ecoli_non_prom.fa.txt\")\n",
    "for chain in data:\n",
    "    headerStr, seq = chain\n",
    "    temp=[]\n",
    "    for i in range (len(seq)-4):\n",
    "        temp1 = []\n",
    "        for j in range (0,4):\n",
    "            if(seq[i+j]=='A'):\n",
    "                temp1.append(0)\n",
    "            if(seq[i+j]=='T'):\n",
    "                temp1.append(1)\n",
    "            if(seq[i+j]=='G'):\n",
    "                temp1.append(2)\n",
    "            if(seq[i+j]=='C'):\n",
    "                temp1.append(3)\n",
    "        #print (temp1)\n",
    "        temp.append(temp1)\n",
    "    training_data2.append(temp)\n",
    "#training_data\n",
    "list_freq1 = []\n",
    "list_freq2 = []\n",
    "\n",
    "for i in training_data1:\n",
    "    temp = []\n",
    "    for j in range (len(list_features)):\n",
    "        temp.append(0)\n",
    "    for j in i:\n",
    "        for k in range (len(list_features)):\n",
    "            if (list_features[k]==j):\n",
    "                temp[k] += 1\n",
    "    list_freq1.append(temp)\n",
    "    \n",
    "for i in training_data2:\n",
    "    temp = []\n",
    "    for j in range (len(list_features)):\n",
    "        temp.append(0)\n",
    "    for j in i:\n",
    "        for k in range (len(list_features)):\n",
    "            if (list_features[k]==j):\n",
    "                temp[k] += 1\n",
    "    list_freq2.append(temp)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "256\n"
     ]
    }
   ],
   "source": [
    "# print(np.shape(list_freq1))\n",
    "# a-0 t-1 g-2 c-3\n",
    "ans=[]\n",
    "cnt=0\n",
    "for i in range(256):\n",
    "    flag=0\n",
    "    temp=list_features[i]\n",
    "    for j in range(838):\n",
    "        if (list_freq1[j][i]==0):\n",
    "            flag=1\n",
    "            break\n",
    "    if(flag==1):\n",
    "        cnt+=1\n",
    "    if (flag==0):\n",
    "        ans.append(temp)\n",
    "    \n",
    "print(ans)\n",
    "print(cnt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[0, 0, 0, 0], 102.97973778307508],\n",
       " [[0, 0, 0, 1], 79.26102502979737],\n",
       " [[0, 0, 1, 1], 73.06317044100119],\n",
       " [[0, 1, 0, 0], 73.7783075089392],\n",
       " [[0, 1, 1, 1], 85.10131108462454],\n",
       " [[1, 0, 0, 0], 72.82479141835518],\n",
       " [[1, 1, 0, 1], 75.92371871275327],\n",
       " [[1, 1, 1, 0], 76.51966626936829],\n",
       " [[1, 1, 1, 1], 114.18355184743741]]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans=np.sum(list_freq1,axis=0)\n",
    "ans=np.divide(ans,8.39)\n",
    "out=[]\n",
    "for i in range(256):\n",
    "    if(ans[i]>70):\n",
    "        out.append([list_features[i],ans[i]])\n",
    "\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 256)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[[2, 3, 3, 0], 71.8],\n",
       " [[3, 0, 2, 3], 88.3],\n",
       " [[3, 2, 3, 3], 80.3],\n",
       " [[3, 3, 0, 2], 87.06666666666666]]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans=np.sum(list_freq2,axis=0)\n",
    "ans=np.divide(ans,30)\n",
    "out=[]\n",
    "for i in range(256):\n",
    "    if(ans[i]>70):\n",
    "        out.append([list_features[i],ans[i]])\n",
    "print(np.shape(list_freq2))\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(839, 256)\n",
      "(839,)\n"
     ]
    }
   ],
   "source": [
    "########### CREATING LABELS FOR THE OUTPUT ###########\n",
    "labels1=[]\n",
    "labels2=[]\n",
    "\n",
    "for i in range(839):\n",
    "    labels1.append(1)\n",
    "for i in range(3000):\n",
    "    labels2.append(0)\n",
    "\n",
    "#### SHUFFLE THE DATA ########    \n",
    "\n",
    "comb=list(zip(list_freq1,labels1))\n",
    "random.shuffle(comb)\n",
    "list_freq1,labels1=zip(*comb)\n",
    "\n",
    "comb=list(zip(list_freq2,labels2))\n",
    "random.shuffle(comb)\n",
    "list_freq2,labels2=zip(*comb)\n",
    "\n",
    "print(np.shape(list_freq1))\n",
    "print(np.shape(labels1))\n",
    "\n",
    "#training_data=np.reshape(training_data,(3839,77*16))\n",
    "\n",
    "#print(np.shape(training_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### SPLITTING DATA INTO TRAIN,VALIDATION AND TEST ############\n",
    "X_train=list()\n",
    "Y_train=list()\n",
    "for i in range(649):\n",
    "    X_train.append(list_freq1[i])\n",
    "    Y_train.append(labels1[i])\n",
    "for i in range(2480):\n",
    "    X_train.append(list_freq2[i])\n",
    "    Y_train.append(labels2[i])\n",
    "\n",
    "\n",
    "# X_train.append(list(list_freq1[:649]))\n",
    "# Y_train.append(list(labels1[:649]))\n",
    "# X_train.append(list(list_freq2[:2480]))\n",
    "# Y_train.append(list(labels2[:2480]))\n",
    "\n",
    "comb=list(zip(X_train,Y_train))\n",
    "random.shuffle(comb)\n",
    "X_train,Y_train=zip(*comb)\n",
    "\n",
    "X_validation=[]\n",
    "Y_validation=[]\n",
    "\n",
    "for i in range(649,720):\n",
    "    X_validation.append(list_freq1[i])\n",
    "    Y_validation.append(labels1[i])\n",
    "for i in range(2480,2740):\n",
    "    X_validation.append(list_freq2[i])\n",
    "    Y_validation.append(labels2[i])\n",
    "# X_validation.append(list_freq1[649:720])\n",
    "# Y_validation.append(labels1[:720])\n",
    "# X_validation.append(list_freq2[2480:2740])\n",
    "# Y_validation.append(labels2[2480:2740])\n",
    "\n",
    "comb=list(zip(X_validation,Y_validation))\n",
    "random.shuffle(comb)\n",
    "X_validation,Y_validation=zip(*comb)\n",
    "\n",
    "X_test=[]\n",
    "Y_test=[]\n",
    "for i in range(720,839):\n",
    "    X_test.append(list_freq1[i])\n",
    "    Y_test.append(labels1[i])\n",
    "for i in range(2740,3000):\n",
    "    X_test.append(list_freq2[i])\n",
    "    Y_test.append(labels2[i])\n",
    "# X_test.append(list_freq1[720:])\n",
    "# Y_test.append(labels1[720:])\n",
    "# X_test.append(list_freq2[2740:])\n",
    "# Y_test.append(labels2[2740:])\n",
    "\n",
    "comb=list(zip(X_test,Y_test))\n",
    "random.shuffle(comb)\n",
    "X_test,Y_test=zip(*comb)\n",
    "\n",
    "X_test=list(X_test)\n",
    "X_validation=list(X_validation)\n",
    "X_train=list(X_train)\n",
    "\n",
    "Y_test=list(Y_test)\n",
    "Y_validation=list(Y_validation)\n",
    "Y_train=list(Y_train)\n",
    "\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "X_valid=np.array(X_validation)\n",
    "X_test=np.array(X_test)\n",
    "\n",
    "Y_test=np.array(Y_test)\n",
    "Y_valid=np.array(Y_validation)\n",
    "Y_train=np.array(Y_train)\n",
    "\n",
    "# X_train=list(X_train)\n",
    "# np.shape(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=0.9,\n",
       "       colsample_bytree=0.9, gamma=0, learning_rate=0.03, max_delta_step=0,\n",
       "       max_depth=2, min_child_weight=6, missing=None, n_estimators=1200,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=3, silent=True,\n",
       "       subsample=1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#XG BOOST\n",
    "#XG BOOST\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "parameters={\n",
    "    \"booster\":'gbtree',\n",
    "    'learning_rate':0.03,\n",
    "    \"n_estimators\":1200,\n",
    "    \"max_depth\":2,\n",
    "    \"seed\":3,\n",
    "    \"min_child_weight\":6,\n",
    "    \n",
    "    \"colsample_bylevel\":0.9,\n",
    "    \"colsample_bytree\":0.9,\n",
    "}\n",
    "\n",
    "model = XGBClassifier(**parameters)\n",
    "model.fit(X_train, Y_train)\n",
    "model\n",
    "\n",
    "# make predictions for test data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[1, 0, 1, 0], 2.3723438],\n",
       " [[1, 0, 1, 1], 4.1347585],\n",
       " [[1, 1, 0, 1], 5.6835904],\n",
       " [[1, 1, 1, 0], 2.3079212],\n",
       " [[3, 0, 2, 3], 3.0149353],\n",
       " [[3, 1, 0, 1], 4.319747],\n",
       " [[3, 3, 0, 2], 3.33228]]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# for layer in model.layers:\n",
    "#     weights=layer.get_weights()\n",
    "#     print(weights)\n",
    "\n",
    "xg_boost_weights=model.feature_importances_\n",
    "xg_boost_weights=np.multiply(xg_boost_weights,100)\n",
    "out_xg=[]\n",
    "for i in range(256):\n",
    "    if(xg_boost_weights[i]>2):\n",
    "        out_xg.append([list_features[i],xg_boost_weights[i]])\n",
    "# print(np.shape(list_freq2))\n",
    "out_xg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(839, 256)\n",
      "(839,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vinayak/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/vinayak/anaconda3/lib/python3.6/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=20, max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=6, min_samples_split=10,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0, warm_start=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##RANDOM FOREST\n",
    "##RANDOM FOREST\n",
    "\n",
    "########### CREATING LABELS FOR THE OUTPUT ###########\n",
    "labels1=[]\n",
    "labels2=[]\n",
    "\n",
    "for i in range(839):\n",
    "    labels1.append(1)\n",
    "for i in range(3000):\n",
    "    labels2.append(0)\n",
    "\n",
    "#### SHUFFLE THE DATA ########    \n",
    "\n",
    "comb=list(zip(list_freq1,labels1))\n",
    "random.shuffle(comb)\n",
    "list_freq1,labels1=zip(*comb)\n",
    "\n",
    "comb=list(zip(list_freq2,labels2))\n",
    "random.shuffle(comb)\n",
    "list_freq2,labels2=zip(*comb)\n",
    "\n",
    "print(np.shape(list_freq1))\n",
    "print(np.shape(labels1))\n",
    "\n",
    "#training_data=np.reshape(training_data,(3839,77*16))\n",
    "\n",
    "#print(np.shape(training_data))\n",
    "\n",
    "\n",
    "####### SPLITTING DATA INTO TRAIN,VALIDATION AND TEST ############\n",
    "X_train=list()\n",
    "Y_train=list()\n",
    "for i in range(649):\n",
    "    X_train.append(list_freq1[i])\n",
    "    Y_train.append(labels1[i])\n",
    "for i in range(2480):\n",
    "    X_train.append(list_freq2[i])\n",
    "    Y_train.append(labels2[i])\n",
    "\n",
    "\n",
    "# X_train.append(list(list_freq1[:649]))\n",
    "# Y_train.append(list(labels1[:649]))\n",
    "# X_train.append(list(list_freq2[:2480]))\n",
    "# Y_train.append(list(labels2[:2480]))\n",
    "\n",
    "comb=list(zip(X_train,Y_train))\n",
    "random.shuffle(comb)\n",
    "X_train,Y_train=zip(*comb)\n",
    "\n",
    "X_validation=[]\n",
    "Y_validation=[]\n",
    "\n",
    "for i in range(649,720):\n",
    "    X_validation.append(list_freq1[i])\n",
    "    Y_validation.append(labels1[i])\n",
    "for i in range(2480,2740):\n",
    "    X_validation.append(list_freq2[i])\n",
    "    Y_validation.append(labels2[i])\n",
    "# X_validation.append(list_freq1[649:720])\n",
    "# Y_validation.append(labels1[:720])\n",
    "# X_validation.append(list_freq2[2480:2740])\n",
    "# Y_validation.append(labels2[2480:2740])\n",
    "\n",
    "comb=list(zip(X_validation,Y_validation))\n",
    "random.shuffle(comb)\n",
    "X_validation,Y_validation=zip(*comb)\n",
    "\n",
    "X_test=[]\n",
    "Y_test=[]\n",
    "for i in range(720,839):\n",
    "    X_test.append(list_freq1[i])\n",
    "    Y_test.append(labels1[i])\n",
    "for i in range(2740,3000):\n",
    "    X_test.append(list_freq2[i])\n",
    "    Y_test.append(labels2[i])\n",
    "# X_test.append(list_freq1[720:])\n",
    "# Y_test.append(labels1[720:])\n",
    "# X_test.append(list_freq2[2740:])\n",
    "# Y_test.append(labels2[2740:])\n",
    "\n",
    "comb=list(zip(X_test,Y_test))\n",
    "random.shuffle(comb)\n",
    "X_test,Y_test=zip(*comb)\n",
    "\n",
    "\n",
    "# X_train=list(X_train)\n",
    "# np.shape(X_train)\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "\n",
    "parameters = {'bootstrap': True,\n",
    "              'min_samples_leaf':6,\n",
    "              'n_estimators': 500, \n",
    "              'min_samples_split': 10,\n",
    "              'max_features': None,\n",
    "              'max_depth': 20,\n",
    "              'warm_start':True\n",
    "             }\n",
    "\n",
    "RF_model = RandomForestClassifier(**parameters)\n",
    "RF_model.fit(X_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[0, 0, 0, 0], 6.664584941559003],\n",
       " [[0, 0, 1, 1], 2.5095249643076345],\n",
       " [[1, 0, 1, 0], 2.160238287803165],\n",
       " [[1, 1, 0, 1], 15.751748560349052],\n",
       " [[3, 0, 2, 3], 5.3299538347423985],\n",
       " [[3, 1, 0, 1], 6.703437386078198],\n",
       " [[3, 2, 3, 3], 2.228481015260176],\n",
       " [[3, 3, 0, 2], 4.090312718606231]]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_weights=RF_model.feature_importances_\n",
    "rf_weights=np.multiply(rf_weights,100)\n",
    "out_rf=[]\n",
    "for i in range(256):\n",
    "    if(rf_weights[i]>2):\n",
    "        out_rf.append([list_features[i],rf_weights[i]])\n",
    "# print(np.shape(list_freq2))\n",
    "out_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
